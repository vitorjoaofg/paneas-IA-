# Corre√ß√£o do Problema de Tool Choice

## üî¥ O PROBLEMA

Voc√™ estava for√ßando o uso da ferramenta com `tool_choice` contendo argumentos pr√©-definidos:

```json
"tool_choice": {
  "type": "function",
  "function": {
    "name": "unimed_consult",
    "arguments": {  // ‚ùå ERRO AQUI!
      "base_url": "https://...",
      "cidade": "Natal_Tasy",
      "cpf": "00835690490",
      // etc...
    }
  }
}
```

Isso faz o modelo SEMPRE retornar aquela `tool_call` exata, independente do input.

## üü¢ A SOLU√á√ÉO

### Op√ß√£o 1: Omitir `tool_choice` completamente (recomendado)

```bash
curl -X POST https://jota.ngrok.app/api/v1/chat/completions \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer token_abc123" \
  -d '{
    "model": "paneas-q32b",
    "messages": [
      {
        "role": "user",
        "content": "oi"
      }
    ],
    "tools": [
      {
        "type": "function",
        "function": {
          "name": "unimed_consult",
          "description": "Consulta dados de benefici√°rio e contratos na API Unimed",
          "parameters": {
            "type": "object",
            "properties": {
              "cidade": {"type": "string"},
              "cpf": {"type": "string"},
              "data_nascimento": {"type": "string"}
            },
            "required": ["cidade", "cpf", "data_nascimento"]
          }
        }
      }
    ]
  }'
```

### Op√ß√£o 2: Usar `tool_choice: "auto"`

```json
{
  "model": "paneas-q32b",
  "messages": [...],
  "tools": [...],
  "tool_choice": "auto"  // Deixa o modelo decidir
}
```

### Op√ß√£o 3: For√ßar uso de tool SEM argumentos (quando necess√°rio)

Se voc√™ REALMENTE precisa for√ßar o uso de uma tool espec√≠fica:

```json
{
  "tool_choice": {
    "type": "function",
    "function": {
      "name": "unimed_consult"
      // SEM "arguments" - o modelo vai gerar baseado no contexto
    }
  }
}
```

## üìã Comportamento Esperado

### Input: "oi"
- **Resposta**: Mensagem de sauda√ß√£o normal
- **tool_calls**: Nenhuma

### Input: "Consulta CPF 00835690490 nascido 28/03/1979 em Natal"
- **Resposta**: `tool_calls` com a fun√ß√£o `unimed_consult`
- **Argumentos gerados pelo modelo**:
  ```json
  {
    "cidade": "Natal_Tasy",
    "cpf": "00835690490",
    "data_nascimento": "19790328"
  }
  ```

### Input: "Qual a capital do Brasil?"
- **Resposta**: "A capital do Brasil √© Bras√≠lia"
- **tool_calls**: Nenhuma

## üîÑ Fluxo Completo Correto

```python
# 1. Usu√°rio envia mensagem
user_input = "Consulta CPF 00835690490..."

# 2. Enviar ao modelo COM tools dispon√≠veis, SEM for√ßar
response = llm.chat({
    "messages": [{"role": "user", "content": user_input}],
    "tools": tools_definitions,
    # "tool_choice": omitido ou "auto"
})

# 3. Verificar se h√° tool_calls
if response.has_tool_calls():
    # 4. Executar a ferramenta
    tool_result = execute_tool(response.tool_calls)

    # 5. Enviar resultado de volta
    final_response = llm.chat({
        "messages": [
            user_message,
            response,  # Com tool_calls
            {"role": "tool", "content": tool_result}
        ]
    })

    # 6. Retornar resposta final humanizada
    return final_response.content
else:
    # N√£o precisou de tool, retornar direto
    return response.content
```

## ‚úÖ Resumo

- **N√ÉO** force `tool_choice` com `arguments` pr√©-definidos
- **DEIXE** o modelo decidir quando usar tools (decis√£o sem√¢ntica)
- **DEIXE** o modelo extrair argumentos do contexto
- **USE** `tool_choice: "auto"` ou omita completamente

Com isso, o modelo vai:
1. Responder "Ol√°!" para "oi"
2. Chamar a tool apenas quando relevante
3. Extrair argumentos do contexto do usu√°rio