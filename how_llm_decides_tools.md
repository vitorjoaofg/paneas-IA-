# Como o LLM Decide Quando/Como Chamar Tools

## üß† 1. Treinamento com Function Calling

O modelo foi treinado com exemplos de **function calling**, aprendendo padr√µes como:

```python
# Durante o treinamento, o modelo viu milh√µes de exemplos assim:

# Exemplo 1: N√ÉO precisa de tool
Input: "Oi, bom dia!"
Output: {"content": "Ol√°! Bom dia! Como posso ajudar?"}

# Exemplo 2: PRECISA de tool
Input: "Qual o clima em S√£o Paulo?"
Output: {
  "tool_calls": [{
    "function": {
      "name": "get_weather",
      "arguments": {"city": "S√£o Paulo"}
    }
  }]
}
```

## üîç 2. An√°lise Sem√¢ntica em Tempo Real

Quando voc√™ envia uma mensagem, o modelo faz uma an√°lise em m√∫ltiplas camadas:

### Passo 1: Identifica√ß√£o de Inten√ß√£o
```python
"Oi"
‚Üí Sauda√ß√£o
‚Üí N√£o precisa de dados externos
‚Üí Responder diretamente

"Consultar CPF 00835690490..."
‚Üí Consulta de dados
‚Üí Men√ß√£o a CPF, data, cidade
‚Üí Matches com descri√ß√£o de unimed_consult
‚Üí Precisa chamar tool
```

### Passo 2: Matching com Descri√ß√µes das Tools

O modelo compara a inten√ß√£o com as descri√ß√µes das ferramentas dispon√≠veis:

```json
{
  "name": "unimed_consult",
  "description": "Consulta dados de benefici√°rio e contratos na API Unimed"
}
```

Palavras-chave detectadas:
- "consultar" ‚Üí match com "Consulta"
- "CPF" ‚Üí match com "benefici√°rio"
- "contrato" ‚Üí match com "contratos"

**Score de relev√¢ncia: ALTO** ‚Üí Usar esta tool

## üéØ 3. Extra√ß√£o de Argumentos

O modelo foi treinado para fazer **Named Entity Recognition (NER)** e **slot filling**:

```python
Input: "Preciso consultar o contrato do CPF 00835690490, nascido em 28/03/1979 em Natal"

# O modelo identifica entidades:
CPF_PATTERN = r'\d{11}'  # ‚Üí 00835690490
DATE_PATTERN = r'\d{2}/\d{2}/\d{4}'  # ‚Üí 28/03/1979
CITY_NAME = "Natal"  # ‚Üí Reconhecimento de cidade

# Mapeia para os par√¢metros da fun√ß√£o:
{
  "cpf": "00835690490",          # Extra√≠do via regex/pattern
  "data_nascimento": "1979-03-28", # Convertido para formato esperado
  "cidade": "Natal"               # Mapeado para "Natal_Tasy"
}
```

## üîß 4. Representa√ß√£o Interna (Embeddings)

O modelo usa embeddings para entender similaridade sem√¢ntica:

```python
# Embedding do input do usu√°rio
user_embedding = embed("consultar contrato CPF...")

# Embeddings das ferramentas dispon√≠veis
tool_embeddings = {
  "unimed_consult": embed("Consulta dados benefici√°rio contratos API Unimed"),
  "weather_tool": embed("Obter previs√£o tempo clima temperatura"),
  "calculator": embed("Calcular matem√°tica n√∫meros opera√ß√µes")
}

# Calcula similaridade cosseno
similarities = cosine_similarity(user_embedding, tool_embeddings)
# unimed_consult: 0.89 (ALTA!)
# weather_tool: 0.12
# calculator: 0.08
```

## üìä 5. Tokens Especiais no Modelo

Modelos com suporte nativo a tools t√™m tokens especiais no vocabul√°rio:

```python
# Tokens especiais adicionados durante fine-tuning
SPECIAL_TOKENS = [
  "<tool_call>",
  "</tool_call>",
  "<function_name>",
  "</function_name>",
  "<arguments>",
  "</arguments>"
]

# O modelo gera internamente algo como:
"""
<tool_call>
  <function_name>unimed_consult</function_name>
  <arguments>{"cpf": "00835690490", ...}</arguments>
</tool_call>
"""
```

## üßÆ 6. Probabilidades de Decis√£o

O modelo calcula probabilidades para cada a√ß√£o poss√≠vel:

```python
# Para input "Oi"
P(resposta_texto) = 0.95     # ‚úÖ Alta probabilidade
P(tool_call) = 0.05          # ‚ùå Baixa probabilidade

# Para input "Consultar CPF..."
P(resposta_texto) = 0.10     # ‚ùå Baixa probabilidade
P(tool_call) = 0.90          # ‚úÖ Alta probabilidade
  P(unimed_consult) = 0.88   # ‚úÖ Espec√≠fico para esta tool
  P(outras_tools) = 0.02     # ‚ùå Baixa para outras
```

## üéì 7. Fine-tuning Espec√≠fico

O modelo passou por fine-tuning com exemplos espec√≠ficos:

```python
training_examples = [
  {
    "input": "V√°rias formas de pedir consulta Unimed",
    "output": "tool_call com argumentos corretos"
  },
  {
    "input": "Sauda√ß√µes e conversas gerais",
    "output": "Resposta direta sem tools"
  },
  # Milhares de varia√ß√µes...
]
```

## üîÑ 8. Fluxo de Decis√£o Completo

```mermaid
graph TD
    A[Input do Usu√°rio] --> B{An√°lise Sem√¢ntica}
    B --> C{Precisa de Tool?}
    C -->|N√£o| D[Gerar Resposta Texto]
    C -->|Sim| E[Identificar Tool]
    E --> F[Extrair Argumentos]
    F --> G[Validar Par√¢metros]
    G --> H[Gerar tool_call JSON]
    H --> I[Runtime Executa]
    I --> J[Resultado volta ao LLM]
    J --> K[Gerar Resposta Final]
```

## üí° 9. Exemplo Pr√°tico de Decis√£o

```python
def llm_decision_process(user_input, available_tools):
    # 1. Tokeniza√ß√£o e embedding
    tokens = tokenize(user_input)
    embedding = encode(tokens)

    # 2. Classifica√ß√£o de inten√ß√£o
    intent = classify_intent(embedding)

    # 3. Decis√£o sobre uso de tools
    if intent.requires_external_data:
        # 4. Sele√ß√£o da tool apropriada
        best_tool = find_best_matching_tool(intent, available_tools)

        # 5. Extra√ß√£o de argumentos
        entities = extract_entities(user_input)
        arguments = map_entities_to_parameters(entities, best_tool.parameters)

        # 6. Gera√ß√£o do tool_call
        return {
            "tool_calls": [{
                "function": {
                    "name": best_tool.name,
                    "arguments": arguments
                }
            }]
        }
    else:
        # Gerar resposta direta
        return {
            "content": generate_text_response(user_input)
        }
```

## üéØ 10. Por que Funciona?

1. **Aten√ß√£o Multi-Head**: O modelo "presta aten√ß√£o" simultaneamente em:
   - Palavras-chave (CPF, contrato, consultar)
   - Estrutura da frase
   - Contexto geral
   - Descri√ß√µes das ferramentas

2. **Transformers**: Permitem entender rela√ß√µes complexas entre tokens distantes

3. **Aprendizado por Refor√ßo**: O modelo foi recompensado por:
   - Usar tools quando apropriado
   - N√£o usar quando desnecess√°rio
   - Extrair argumentos corretamente

## üìù Resumo

O LLM sabe quando/como chamar tools atrav√©s de:

1. **Treinamento especializado** com milh√µes de exemplos
2. **An√°lise sem√¢ntica** da inten√ß√£o do usu√°rio
3. **Matching** entre input e descri√ß√µes das tools
4. **Extra√ß√£o inteligente** de entidades e argumentos
5. **Tokens especiais** para estruturar tool_calls
6. **C√°lculo de probabilidades** para tomar decis√µes

√â como se o modelo tivesse aprendido a pensar:
- "Isso parece uma sauda√ß√£o ‚Üí respondo direto"
- "Isso parece consulta de dados ‚Üí preciso da tool unimed_consult"
- "Vejo CPF, data e cidade ‚Üí extraio e formato para a API"