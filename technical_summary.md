# Como o LLM Sabe Quando/Como Chamar Tools - Resumo T√©cnico

## üß† Mecanismo Principal

O LLM usa **3 componentes principais** para decidir:

### 1. **Pattern Matching Sem√¢ntico**
```python
# O modelo foi treinado para reconhecer padr√µes:
"consultar CPF" ‚Üí tool_call
"oi/ol√°"       ‚Üí resposta direta
"qual clima"   ‚Üí tool_call (weather)
```

### 2. **Embeddings e Similaridade**
```python
# Cada input √© convertido em vetor num√©rico
input_embedding = [0.9, 0.0, 0.8, 0.0, 0.1]  # "consultar CPF..."

# Compara com embeddings das tools dispon√≠veis
tool_embeddings = {
    "unimed_consult": [0.8, 0.2, 0.9, 0.1, 0.7],  # Alta similaridade!
    "weather":        [0.1, 0.9, 0.2, 0.8, 0.3]   # Baixa similaridade
}

# Calcula score de similaridade cosseno
score(input, unimed_consult) = 0.85  # ‚úÖ Usar esta tool
score(input, weather) = 0.16         # ‚ùå N√£o relevante
```

### 3. **Named Entity Recognition (NER)**
```python
# Extrai entidades do texto
"CPF 00835690490, nascido em 28/03/1979 em Natal"
‚Üì
{
    "CPF": "00835690490",
    "DATA": "28/03/1979",
    "CIDADE": "Natal"
}
‚Üì
# Mapeia para par√¢metros da fun√ß√£o
{
    "cpf": "00835690490",
    "data_nascimento": "1979-03-28",
    "cidade": "Natal_Tasy"
}
```

## üîÑ Fluxo de Decis√£o

```
Input: "Consultar CPF 00835690490..."
    ‚Üì
[TOKENIZA√á√ÉO] ‚Üí ['consultar', 'cpf', '00835690490', ...]
    ‚Üì
[EMBEDDING] ‚Üí [0.9, 0.0, 0.8, 0.0, 0.1]
    ‚Üì
[SIMILARITY CHECK]
    ‚Ä¢ unimed_consult: 0.85 ‚úÖ
    ‚Ä¢ weather: 0.16
    ‚Ä¢ calculator: 0.28
    ‚Üì
[DECISION: score > 0.5] ‚Üí USE TOOL
    ‚Üì
[EXTRACT ENTITIES] ‚Üí {cpf, data_nascimento, cidade}
    ‚Üì
[BUILD ARGUMENTS] ‚Üí {"cpf": "00835690490", ...}
    ‚Üì
[GENERATE JSON] ‚Üí tool_call structure
```

## üéØ Treinamento Espec√≠fico

O modelo foi treinado com **milh√µes de exemplos** como:

```json
// Exemplo de treinamento 1
{
  "input": "oi",
  "output": {"content": "Ol√°! Como posso ajudar?"}
}

// Exemplo de treinamento 2
{
  "input": "consultar CPF 12345678901",
  "output": {
    "tool_calls": [{
      "function": {
        "name": "unimed_consult",
        "arguments": {"cpf": "12345678901", ...}
      }
    }]
  }
}
```

## üî¨ Por Dentro do Transformer

### Attention Mechanism
O modelo "presta aten√ß√£o" em m√∫ltiplas partes simultaneamente:
- **Palavras-chave**: "consultar", "CPF", "contrato"
- **Descri√ß√£o da tool**: "Consulta dados de benefici√°rio"
- **Contexto**: Rela√ß√£o entre palavras

### Multi-Head Attention
```python
# Cada "head" foca em aspectos diferentes:
head_1: Foco em entidades (CPF, datas)
head_2: Foco em a√ß√µes (consultar, verificar)
head_3: Foco em contexto (Unimed, contratos)
head_4: Foco em localiza√ß√£o (Natal, cidade)
```

## üìä Decis√£o Final

```python
def should_use_tool(input_text, available_tools):
    # 1. Embedding do input
    input_emb = model.encode(input_text)

    # 2. Para cada tool dispon√≠vel
    best_match = None
    best_score = 0.0

    for tool in available_tools:
        # 3. Calcula similaridade
        score = cosine_similarity(input_emb, tool.embedding)

        if score > best_score:
            best_score = score
            best_match = tool

    # 4. Threshold de decis√£o
    if best_score > 0.5:  # Threshold aprendido
        # 5. Extrai argumentos
        entities = extract_entities(input_text)
        arguments = map_to_parameters(entities, best_match)

        return {
            "tool_calls": [{
                "function": {
                    "name": best_match.name,
                    "arguments": arguments
                }
            }]
        }
    else:
        # Gera resposta direta
        return {"content": generate_response(input_text)}
```

## üéì Conceitos-Chave

1. **Fine-tuning**: Modelo ajustado especificamente para function calling
2. **Embeddings**: Representa√ß√£o vetorial do significado
3. **Threshold**: Valor limite para decis√£o (geralmente ~0.5)
4. **Slot Filling**: Preenchimento autom√°tico de par√¢metros
5. **Tokens Especiais**: `<tool_call>`, `</tool_call>` no vocabul√°rio

## ‚ö° Performance

- **Lat√™ncia**: ~100-500ms para decis√£o
- **Precis√£o**: ~95%+ em casos bem definidos
- **Embeddings**: Vetores de 4096+ dimens√µes
- **Contexto**: At√© 128k tokens de janela

## üîë Resumo Final

O LLM decide usar tools atrav√©s de:
1. **An√°lise sem√¢ntica** do input
2. **Compara√ß√£o de embeddings** com tools dispon√≠veis
3. **Score de similaridade** > threshold
4. **Extra√ß√£o autom√°tica** de argumentos
5. **Gera√ß√£o estruturada** do JSON

Tudo isso acontece em **uma √∫nica forward pass** pela rede neural!